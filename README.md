# ğŸŸ¡ğŸŸ¢ Grooky â€” Tu asistente conversacional con voz + UI web > **Habla. Escucha. Ve.** > Grooky une **Siri (Atajos)**, **Groq** y una **UI de chat** ultraligera para darte respuestas con **voz** y **formato rico** (Markdown, tablas, cÃ³digo), en un flujo pensado para mÃ³vil. !Grooky Cover --- ## âœ¨ Por quÃ© te va a encantar - **Arranque por voz**: dicta a Siri; Grooky responde **en voz** y la conversaciÃ³n se **siembra** en la UI (primer turno `u/a`) sin recalcular. - **Formato pro**: render Markdown **seguro** (negritas, listas, **tablas**, `code`, enlaces) y efecto **typing** agradable. - **Historial por hilo**: cada conversaciÃ³n vive en `localStorage` con su propio `id` (ideal para reanudar). - **MicrÃ³fono inâ€‘app**: botÃ³n ğŸ™ï¸ minimal con *fallback* a **Safari** cuando la Vista Web de Atajos no soporta dictado. - **DiseÃ±o con personalidad**: orbe animado **amarillo + verdeâ€‘azul** estilo Siri, tema oscuro y UX compacta. --- ## ğŸ§ª Demo rÃ¡pida - UI vacÃ­a **`https://siri-gpt.vercel.app/ui.html`** - Sembrado (caso 2; abre en Safari): https://siri-gpt.vercel.app/ui.html ?u=Hola%20Grooky &a=%2A%2ARespuesta%2A%2A%20con%20%60c%C3%B3digo%60%20y%20tabla%3A%0A%0A%7CCol1%7CCol2%7C%0A%7C---%7C---%7C%0A%7CA%7CB%7C &id=hilo-demo &model=llama-3.3-70b-versatile &speed=18 &chunk=2
> ğŸ’¡ Usa `&reset=1` solo la **primera** vez con cada `id` si quieres arrancar limpio. --- ## ğŸš€ QuÃ© resuelve (y cÃ³mo) 1. **Quiero hablar y que me contesten por voz** â†’ Atajos hace `POST /api/siri-gpt` con tu dictado y Siri lee la respuesta. 2. **Quiero seguir en pantalla** â†’ la UI abre con `u=` y `a=` ya puestos; ves tu pregunta y el typing de la respuesta **sin recalcular**. 3. **Quiero formato bonito** â†’ Markdown seguro con **DOMPurify**; tabla/cÃ³digo/citas/listas se ven perfectos. 4. **Quiero retomar mÃ¡s tarde** â†’ cada hilo tiene su `id`; la conversaciÃ³n queda en `localStorage`. --- ## ğŸ§© Arquitectura Atajo (iOS) â”œâ”€ Dictas â†’ PREGUNTA â”œâ”€ POST /api/siri-gpt { message: PREGUNTA } â†’ RESPUESTA â”œâ”€ Siri lee RESPUESTA (voz) â””â”€ Abre UI: /ui.html?u=&a=&id=
UI (ESM + mÃ³dulos) â”œâ”€ Siembra primer turno (u/a) con typing + Markdown â”œâ”€ Historial por id (localStorage) â”œâ”€ Turnos siguientes â†’ POST /api/siri-gpt { messages[] } â””â”€ Mic inâ€‘app (fallback a Safari si no hay Speech API)
Serverless (Vercel) â””â”€ /api/siri-gpt â†’ Groq (OpenAIâ€‘like) â†’ { response }
--- ## ğŸ§­ ParÃ¡metros de la UI | parÃ¡metro | quÃ© hace | ejemplo | |---|---|---| | `u` | primer mensaje del usuario (acepta `q`) | `u=Hola%20Grooky` | | `a` | primera respuesta ya calculada | `a=%2A%2AOK%2A%2A` | | `id` | identificador del hilo (localStorage) | `id=hilo1` | | `reset` | `1` limpia el hilo `id` al abrir | `reset=1` | | `model` | modelo Groq | `llama-3.3-70b-versatile` | | `speed` | ms por tick typing (default `18`) | `speed=18` | | `chunk` | chars por tick typing (default `2`) | `chunk=2` | | `title` | tÃ­tulo de la UI | `title=Grooky` | | `voice` | idioma dictado | `es-ES` | **Ejemplo:** `/ui.html?u=Hola%20Grooky&a=**OK**&id=hilo1&model=llama-3.3-70b-versatile&speed=18&chunk=2` --- ## ğŸ¤ Atajos (Shortcuts) â€“ Caso 2 (voz + sembrado) **Flujo recomendado:** 1. **Dictar texto** â†’ `PREGUNTA` 2. **POST** a `https://siri-gpt.vercel.app/api/siri-gpt` con body: ```json { "message": "PREGUNTA" } â†’ devuelve RESPUESTA 3. Hablar texto â†’ RESPUESTA (sin â€œesperar hasta que acabeâ€ o usa â€œHablar textoâ€). 4. Codificar URL â†’ PREGUNTA â†’ PREG_URL 5. Codificar URL â†’ RESPUESTA â†’ RESP_URL 6. Mostrar vista web con:
https://siri-gpt.vercel.app/ui.html?u=&a=&id=hilo1&model=llama-3.3-70b-versatile&speed=18&chunk=2 (opcional primera vez con ese id: &reset=1)
Evita 404: sin espacios â€œsueltosâ€; codifica ** â†’ %2A%2A, | â†’ %7C, Ã³ â†’ %C3%B3.
â¸»
ğŸ”Œ API
POST https://siri-gpt.vercel.app/api/siri-gpt
- Turno Ãºnico:
{ "message": "..." } - Chat:
{ "model": "llama-3.3-70b-versatile", "messages": [ {"role":"system","content":"Eres un asistente Ãºtil y conciso."}, {"role":"user","content":"Hola"} ], "temperature": 0.4 } Respuesta:
{ "response": "..." } El backend sanea a { role, content } antes de llamar a Groq. Errores siempre en JSON.
â¸»
ğŸ§° Despliegue
- Hosting: Vercel (Node â‰¥ 18).
- Env: GROQ_API_KEY en Project â†’ Settings â†’ Environment Variables.
- URL: https://siri-gpt.vercel.app/ui.html
Durante desarrollo, puedes forzar recarga con ?v=YYYYMMDD en CSS/JS y poner no-store temporal en vercel.json.
â¸»
ğŸ”’ Privacidad & seguridad
- Historial en localStorage (por id) en el navegador.
- Markdown sanitizado con DOMPurify.
- Cabeceras antiâ€‘sniff y referrer limitado.
- Respeta prefers-reduced-motion y accesibilidad bÃ¡sica (focus visible, aria-live).
â¸»
ğŸ“¸ Capturas (sugerencia)
Coloca estas imÃ¡genes en /assets/ y enlÃ¡zalas:
- assets/cover.png â€” hero image de Grooky
- assets/chat.png â€” conversaciÃ³n con tabla/cÃ³digo
- assets/voice.png â€” dictado + UI
!Chat con tablas â¸»
ğŸ Troubleshooting
- No se ve la respuesta de la IA â†’ en chat.css usa:
.msg:has(.text:not(.typing):empty) { display: none; } - Logo gigante â†’ fuerza tamaÃ±o:
#grookyCanvas{ width:30px; height:30px; max-width:30px; max-height:30px; } - Se mezclan conversaciones â†’ usa id Ãºnico o &reset=1 al abrir.
- Dictado no va en Atajos â†’ limitaciÃ³n de WKWebView; la UI abrirÃ¡ Safari como fallback.
â¸»
ğŸ—ºï¸ Roadmap
- Streaming SSE (tokens en tiempo real)
- BotÃ³n Nuevo chat (genera id nuevo)
- Export a JSON/Markdown
- Tema claro/oscuro automÃ¡tico
â¸»
ğŸ§‘â€ğŸ’» Autor
Grooky â€” by Hugo VÃ¡zquez Docampo
Si te mola, â­ï¸ al repo y cuÃ©ntame quÃ© feature te gustarÃ­a ver.
â¸»
ğŸ“„ Licencia
MIT â€” ÃºÂ­salo libremente y construye encima.
â¸»
Â¿Listo para hablar con Grooky? ğŸ‘‰ https://siri-gpt.vercel.app/ui.html

